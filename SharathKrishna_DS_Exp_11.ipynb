{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Bagging Rainforest"
      ],
      "metadata": {
        "id": "f37TUAa4ubYR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vclruRamuRAS",
        "outputId": "f391613d-0cb9-4254-a688-330fbeafb40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging model accuracy: 1.0000\n",
            "Random Forest model accuracy: 1.0000\n",
            "Feature importances from Random Forest: [0.10410501 0.04460499 0.41730813 0.43398187]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Bagging and RandomForest models\n",
        "bagging_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Bagging model\n",
        "bagging_model.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "# Train the Random Forest model\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# Output the accuracy results\n",
        "print(f\"Bagging model accuracy: {bagging_accuracy:.4f}\")\n",
        "print(f\"Random Forest model accuracy: {rf_accuracy:.4f}\")\n",
        "\n",
        "# Feature importance from Random Forest\n",
        "importances = random_forest_model.feature_importances_\n",
        "print(f\"Feature importances from Random Forest: {importances}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting Xgboost"
      ],
      "metadata": {
        "id": "0mk0QR-GuuUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Output the accuracy result\n",
        "print(f\"XGBoost model accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "# Feature importance from XGBoost\n",
        "importances_xgb = xgb_model.feature_importances_\n",
        "print(f\"Feature importances from XGBoost: {importances_xgb}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpslFzEqum7S",
        "outputId": "0a6971f7-bd81-4bf2-a1f6-2c4ae93d7a47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost model accuracy: 1.0000\n",
            "Feature importances from XGBoost: [0.01012843 0.0303854  0.73876214 0.22072402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [04:56:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking Logistic Regressor and KNN"
      ],
      "metadata": {
        "id": "PqpjrIDdu1le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the base models (Logistic Regression and KNN)\n",
        "base_learners = [\n",
        "    ('logreg', LogisticRegression(max_iter=1000)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "]\n",
        "\n",
        "# Initialize the meta-model (Logistic Regression)\n",
        "meta_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Create the Stacking model\n",
        "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
        "\n",
        "# Train the stacking model\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "stacking_accuracy = accuracy_score(y_test, y_pred_stacking)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Stacking model accuracy: {stacking_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAmWyrQCuxX8",
        "outputId": "6d01c6de-8df2-46b0-8a98-f8eb70b5c09d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking model accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hORR4gKNu89q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}